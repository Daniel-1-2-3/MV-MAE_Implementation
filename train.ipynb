{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cde2433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading dataset...\n",
      "Running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 0/1940 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.8695, 0.8418, 1.1450,  ..., 0.8192, 0.8998, 0.7591],\n",
      "        [0.8962, 0.8875, 1.0954,  ..., 0.8095, 0.8985, 0.7987],\n",
      "        [0.8799, 0.8452, 1.1574,  ..., 0.7879, 0.8865, 0.8027],\n",
      "        ...,\n",
      "        [0.8773, 0.8605, 1.1121,  ..., 0.7834, 0.9086, 0.7851],\n",
      "        [0.8816, 0.8670, 1.1158,  ..., 0.7780, 0.9120, 0.8171],\n",
      "        [0.8692, 0.8726, 1.1237,  ..., 0.8279, 0.8922, 0.7734]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 1/1940 [00:40<21:54:28, 40.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.8507, 0.8494, 1.0568,  ..., 0.6868, 0.8469, 0.8784],\n",
      "        [0.8455, 0.8849, 1.0317,  ..., 0.6963, 0.8785, 0.8832],\n",
      "        [0.8877, 0.8663, 1.0305,  ..., 0.7273, 0.8526, 0.8719],\n",
      "        ...,\n",
      "        [0.8956, 0.8831, 1.0335,  ..., 0.7335, 0.8468, 0.8785],\n",
      "        [0.8428, 0.8842, 1.0656,  ..., 0.6992, 0.8307, 0.8826],\n",
      "        [0.8406, 0.9072, 1.0587,  ..., 0.7258, 0.8557, 0.8775]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 2/1940 [00:50<12:03:48, 22.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.8425, 0.9526, 1.0207,  ..., 0.7552, 0.8527, 0.8745],\n",
      "        [0.8524, 0.8906, 1.0457,  ..., 0.7516, 0.8523, 0.8456],\n",
      "        [0.8564, 0.8995, 1.0404,  ..., 0.7459, 0.8675, 0.8684],\n",
      "        ...,\n",
      "        [0.9044, 0.8993, 1.0208,  ..., 0.7792, 0.8698, 0.7905],\n",
      "        [0.8820, 0.8892, 1.0273,  ..., 0.7441, 0.8039, 0.8760],\n",
      "        [0.8740, 0.8761, 1.0439,  ..., 0.7301, 0.8618, 0.8180]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 3/1940 [00:53<7:17:22, 13.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.8445, 0.8964, 1.0812,  ..., 0.7439, 0.8057, 0.8408],\n",
      "        [0.8381, 0.9037, 1.0638,  ..., 0.7329, 0.8122, 0.8752],\n",
      "        [0.8673, 0.8981, 1.0868,  ..., 0.7371, 0.8596, 0.7948],\n",
      "        ...,\n",
      "        [0.8464, 0.8977, 1.0901,  ..., 0.6996, 0.8440, 0.8150],\n",
      "        [0.8900, 0.8692, 1.0908,  ..., 0.7333, 0.8733, 0.8377],\n",
      "        [0.8203, 0.8792, 1.0825,  ..., 0.6848, 0.8316, 0.8399]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 4/1940 [00:57<5:20:09,  9.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.9108, 0.8984, 0.9937,  ..., 0.8057, 0.8656, 0.9331],\n",
      "        [0.9136, 0.9172, 0.9741,  ..., 0.8186, 0.8580, 0.9194],\n",
      "        [0.9176, 0.9561, 0.9949,  ..., 0.7843, 0.8269, 0.9181],\n",
      "        ...,\n",
      "        [0.9139, 0.9184, 0.9864,  ..., 0.8027, 0.8186, 0.9403],\n",
      "        [0.9626, 0.9383, 1.0007,  ..., 0.8030, 0.8736, 0.8810],\n",
      "        [0.9312, 0.9207, 1.0045,  ..., 0.7342, 0.8117, 0.9060]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 5/1940 [01:00<3:57:42,  7.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[1.0227, 0.9015, 0.9250,  ..., 0.7894, 0.8412, 0.8896],\n",
      "        [0.9120, 0.9110, 0.8751,  ..., 0.8149, 0.8662, 0.9671],\n",
      "        [0.8977, 0.8910, 0.9054,  ..., 0.8694, 0.8458, 0.9772],\n",
      "        ...,\n",
      "        [1.0273, 0.9353, 0.8993,  ..., 0.7946, 0.8327, 0.9360],\n",
      "        [0.9333, 0.9142, 0.9104,  ..., 0.8016, 0.8422, 0.9052],\n",
      "        [0.9442, 0.9192, 0.8919,  ..., 0.7830, 0.8542, 0.9110]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 6/1940 [01:03<3:10:35,  5.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[0.9342, 0.8973, 0.8687,  ..., 0.7556, 0.8573, 0.8716],\n",
      "        [0.9061, 0.9368, 0.8265,  ..., 0.7986, 0.9152, 0.8606],\n",
      "        [0.8841, 0.8947, 0.8511,  ..., 0.7566, 0.8875, 0.8765],\n",
      "        ...,\n",
      "        [0.9233, 0.8899, 0.8256,  ..., 0.7765, 0.8560, 0.8411],\n",
      "        [0.9041, 0.8914, 0.8457,  ..., 0.7150, 0.8477, 0.8162],\n",
      "        [0.9011, 0.8712, 0.8704,  ..., 0.7715, 0.8691, 0.8958]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 7/1940 [01:06<2:43:33,  5.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[1.0080, 0.9236, 0.8115,  ..., 0.8070, 0.8855, 0.8699],\n",
      "        [0.9650, 0.9693, 0.7847,  ..., 0.7707, 0.8713, 0.9053],\n",
      "        [0.9865, 0.9387, 0.7852,  ..., 0.7581, 0.8647, 0.8874],\n",
      "        ...,\n",
      "        [1.0017, 0.9392, 0.8053,  ..., 0.8236, 0.8844, 0.8950],\n",
      "        [0.9595, 0.9318, 0.8083,  ..., 0.7515, 0.8634, 0.9393],\n",
      "        [0.9793, 0.9362, 0.8222,  ..., 0.8309, 0.9102, 0.9041]],\n",
      "       grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      8\u001b[0m         img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      9\u001b[0m         encoder_embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m384\u001b[39m, encoder_num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     10\u001b[0m         decoder_embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, decoder_num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     11\u001b[0m         base_dataset_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0006\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Daniel\\High School\\Research\\MV_MAE_Implementation\\train_setup.py:55\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, num_epochs, lr)\u001b[0m\n\u001b[0;32m     53\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x1, x2)\n\u001b[0;32m     54\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_loss(out)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     58\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train_setup import Trainer\n",
    "import os\n",
    "\n",
    "trainer = Trainer(\n",
    "        img_size=64, patch_size=8, batch_size=16, in_channels=3,\n",
    "        encoder_embed_dim=384, encoder_num_heads=8,\n",
    "        decoder_embed_dim=256, decoder_num_heads=4,\n",
    "        base_dataset_dir=os.path.join(os.getcwd(), 'dataset')\n",
    "    )\n",
    "\n",
    "trainer.train(num_epochs=50, lr=0.0006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa35b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3d05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
