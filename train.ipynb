{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cde2433d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Loading dataset...\n",
      "Running on cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 0/1940 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[2711766.7500, 3240985.7500, 2805237.7500,  ..., 2101493.0000,\n",
      "         4524610.0000, 1971923.3750],\n",
      "        [2890188.5000, 3422637.5000, 2609479.0000,  ..., 2308143.5000,\n",
      "         4677955.5000, 2052014.5000],\n",
      "        [2736198.5000, 3203951.2500, 2804732.5000,  ..., 2317962.5000,\n",
      "         4541900.5000, 1891956.7500],\n",
      "        ...,\n",
      "        [2762043.2500, 3339207.2500, 2684213.5000,  ..., 2217486.5000,\n",
      "         4507216.5000, 1987203.5000],\n",
      "        [2710634.2500, 3353766.5000, 2775928.2500,  ..., 2043399.3750,\n",
      "         4649271.5000, 2125351.7500],\n",
      "        [2876360.0000, 3353390.2500, 2633222.2500,  ..., 2198539.5000,\n",
      "         4729997.0000, 2251582.7500]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 1/1940 [01:01<32:55:16, 61.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[5873648.5000, 2958181.0000, 1776780.7500,  ..., 2280492.0000,\n",
      "         6710526.5000, 4267456.5000],\n",
      "        [5617038.0000, 2971937.5000, 1591238.3750,  ..., 1768620.0000,\n",
      "         6367285.0000, 3987650.2500],\n",
      "        [6113545.5000, 2961189.7500, 1755817.7500,  ..., 2114766.5000,\n",
      "         7106333.0000, 4360275.0000],\n",
      "        ...,\n",
      "        [5571496.0000, 2656801.0000, 1707194.5000,  ..., 1987298.1250,\n",
      "         6589446.0000, 3976378.2500],\n",
      "        [5835651.0000, 2852748.7500, 1582800.7500,  ..., 2468698.5000,\n",
      "         7429375.0000, 4354213.0000],\n",
      "        [5807011.0000, 2823947.0000, 1788412.1250,  ..., 2669091.7500,\n",
      "         7795316.0000, 4313445.5000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 2/1940 [01:04<14:32:51, 27.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 6473684.0000, 14902669.0000,  1774060.0000,  ...,\n",
      "          6231575.0000, 15894428.0000, 11946921.0000],\n",
      "        [ 6152116.0000, 14689828.0000,  1864206.6250,  ...,\n",
      "          6772414.0000, 15843050.0000, 11867254.0000],\n",
      "        [ 5957280.5000, 14978031.0000,  1861278.1250,  ...,\n",
      "          7127457.0000, 15758828.0000, 11941773.0000],\n",
      "        ...,\n",
      "        [ 5932924.5000, 14802730.0000,  1893966.1250,  ...,\n",
      "          7422893.5000, 16214891.0000, 11856544.0000],\n",
      "        [ 6189618.0000, 14567674.0000,  1824933.2500,  ...,\n",
      "          6773689.0000, 15519205.0000, 11701845.0000],\n",
      "        [ 6239705.5000, 14474001.0000,  1678835.8750,  ...,\n",
      "          7328801.5000, 16404338.0000, 11829451.0000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 3/1940 [01:07<8:39:08, 16.08s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 3879228.2500,  2647422.7500,  2984270.0000,  ...,\n",
      "          3462460.5000, 11074796.0000,  7636809.0000],\n",
      "        [ 4030133.5000,  2394300.5000,  2986069.5000,  ...,\n",
      "          3995940.0000, 11554345.0000,  7609205.0000],\n",
      "        [ 3947631.5000,  2314050.0000,  3239821.2500,  ...,\n",
      "          3591255.2500, 11331741.0000,  7857434.0000],\n",
      "        ...,\n",
      "        [ 3903772.5000,  2422363.0000,  3030715.5000,  ...,\n",
      "          3990762.2500, 11145518.0000,  7721070.5000],\n",
      "        [ 4081790.5000,  2500673.0000,  3057415.7500,  ...,\n",
      "          4905603.0000, 12865807.0000,  7569324.5000],\n",
      "        [ 4147964.2500,  2439753.0000,  2990903.2500,  ...,\n",
      "          5882003.5000, 13775388.0000,  7749570.5000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 4/1940 [01:10<5:50:49, 10.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 1545955.3750, 10809094.0000,  5836027.0000,  ...,\n",
      "          9267879.0000, 23560414.0000, 14018497.0000],\n",
      "        [ 1333618.5000, 11109042.0000,  5644210.0000,  ...,\n",
      "          9496931.0000, 23285350.0000, 14100739.0000],\n",
      "        [ 1426293.5000, 11372885.0000,  5902685.5000,  ...,\n",
      "          9483277.0000, 23293708.0000, 14419285.0000],\n",
      "        ...,\n",
      "        [ 2043475.2500, 10716634.0000,  5724297.0000,  ...,\n",
      "         10552044.0000, 25337884.0000, 13882950.0000],\n",
      "        [ 1603501.7500, 10742842.0000,  5669582.5000,  ...,\n",
      "          9759952.0000, 23664422.0000, 14085849.0000],\n",
      "        [ 1826089.1250, 11001503.0000,  5425882.0000,  ...,\n",
      "         10705271.0000, 25334670.0000, 13960098.0000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 5/1940 [01:13<4:26:27,  8.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[  905882.3125, 11235913.0000,  8725978.0000,  ...,\n",
      "          9222103.0000, 25436016.0000, 12177622.0000],\n",
      "        [  939317.1875, 11345880.0000,  8658773.0000,  ...,\n",
      "          9582741.0000, 25324762.0000, 12350653.0000],\n",
      "        [ 1001335.6250, 10810808.0000,  8445546.0000,  ...,\n",
      "          9617647.0000, 26935828.0000, 11940159.0000],\n",
      "        ...,\n",
      "        [ 1099570.8750, 11354130.0000,  8335310.5000,  ...,\n",
      "          9608857.0000, 25571852.0000, 12255383.0000],\n",
      "        [  960540.5625, 11272543.0000,  8389334.0000,  ...,\n",
      "          9235014.0000, 25347878.0000, 12199564.0000],\n",
      "        [  914303.6875, 10797252.0000,  8541984.0000,  ...,\n",
      "          9745449.0000, 26853176.0000, 12357210.0000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 6/1940 [01:17<3:31:32,  6.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 1258853.5000,  2520794.0000,  7554087.0000,  ...,\n",
      "          6779305.5000, 15707401.0000,  5766196.5000],\n",
      "        [ 1168230.3750,  2626464.0000,  7496216.5000,  ...,\n",
      "          7180491.5000, 15981723.0000,  6112031.0000],\n",
      "        [ 1324769.6250,  2347152.5000,  7644764.0000,  ...,\n",
      "          6980740.0000, 15631007.0000,  6003716.0000],\n",
      "        ...,\n",
      "        [ 1556018.5000,  2501240.2500,  7611285.5000,  ...,\n",
      "          7650618.5000, 18433342.0000,  5895453.0000],\n",
      "        [ 1174547.0000,  2679054.7500,  7641816.5000,  ...,\n",
      "          6501190.0000, 16269714.0000,  6085103.0000],\n",
      "        [ 1436285.7500,  2247748.7500,  7564262.0000,  ...,\n",
      "          7181494.0000, 16334561.0000,  6192530.5000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 7/1940 [01:20<2:53:35,  5.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 4201303.5000, 11842136.0000, 10383453.0000,  ...,\n",
      "         11350987.0000, 26620836.0000, 11039419.0000],\n",
      "        [ 4153889.0000, 11916565.0000, 10537236.0000,  ...,\n",
      "         12093961.0000, 28758548.0000, 11192030.0000],\n",
      "        [ 4494092.0000, 12162077.0000, 10442020.0000,  ...,\n",
      "         11390061.0000, 26441504.0000, 10998939.0000],\n",
      "        ...,\n",
      "        [ 4380905.0000, 12185940.0000, 10538454.0000,  ...,\n",
      "         11446608.0000, 26674096.0000, 10919922.0000],\n",
      "        [ 4233623.0000, 12121657.0000, 10197471.0000,  ...,\n",
      "         12066031.0000, 28640272.0000, 11356134.0000],\n",
      "        [ 4430916.0000, 12115309.0000, 10698742.0000,  ...,\n",
      "         11766847.0000, 26684660.0000, 11178062.0000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1 - Training:   0%|          | 8/1940 [01:23<2:29:26,  4.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "std tensor([[ 5393667.0000, 10896604.0000, 10006386.0000,  ...,\n",
      "         12068716.0000, 30160122.0000, 10763886.0000],\n",
      "        [ 6113134.5000, 11385989.0000, 10303723.0000,  ...,\n",
      "         11641610.0000, 28042366.0000, 11024273.0000],\n",
      "        [ 6209199.0000, 11464722.0000, 10468257.0000,  ...,\n",
      "         11721114.0000, 28239254.0000, 10570611.0000],\n",
      "        ...,\n",
      "        [ 5924437.5000, 11275331.0000, 10757545.0000,  ...,\n",
      "         11698417.0000, 27571222.0000, 10899312.0000],\n",
      "        [ 6083792.0000, 11139381.0000, 10530573.0000,  ...,\n",
      "         12035101.0000, 28505450.0000, 10998960.0000],\n",
      "        [ 5854015.5000, 10769937.0000, 10077513.0000,  ...,\n",
      "         12139977.0000, 29991246.0000, 10689656.0000]], grad_fn=<StdBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 14\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[0;32m      8\u001b[0m         img_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, patch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, in_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m      9\u001b[0m         encoder_embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m384\u001b[39m, encoder_num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m,\n\u001b[0;32m     10\u001b[0m         decoder_embed_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m, decoder_num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,\n\u001b[0;32m     11\u001b[0m         base_dataset_dir\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39mgetcwd(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     12\u001b[0m     )\n\u001b[1;32m---> 14\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0006\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Daniel\\High School\\Research\\MV_MAE_Implementation\\train_setup.py:55\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, num_epochs, lr)\u001b[0m\n\u001b[0;32m     53\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x1, x2)\n\u001b[0;32m     54\u001b[0m loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_loss(out)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     58\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\danie_gfshjqx\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\autograd\\graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from train_setup import Trainer\n",
    "import os\n",
    "\n",
    "trainer = Trainer(\n",
    "        img_size=64, patch_size=8, batch_size=16, in_channels=3,\n",
    "        encoder_embed_dim=384, encoder_num_heads=8,\n",
    "        decoder_embed_dim=256, decoder_num_heads=4,\n",
    "        base_dataset_dir=os.path.join(os.getcwd(), 'dataset')\n",
    "    )\n",
    "\n",
    "trainer.train(num_epochs=50, lr=0.0006)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffa35b1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3d05d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
